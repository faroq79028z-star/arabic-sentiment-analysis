"""
Sentiment Analysis Model
========================

This module contains the SentimentClassifier class for Arabic text sentiment analysis.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
import joblib
from pathlib import Path
import numpy as np

class SentimentClassifier:
    """
    A sentiment analysis classifier for Arabic text using TF-IDF and Naive Bayes.
    
    This class provides a complete pipeline for:
    - Text preprocessing and feature extraction using TF-IDF
    - Classification using Multinomial Naive Bayes
    - Model training, evaluation, and persistence
    
    Attributes:
        pipeline: sklearn Pipeline containing TF-IDF vectorizer and classifier
    """
    
    def __init__(self):
        """
        Initialize the sentiment classifier with a TF-IDF + Naive Bayes pipeline.
        """
        print("ğŸ”§ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ pipeline Ù…ØªÙƒØ§Ù…Ù„
        self.pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                # Ù…Ø¹Ù„Ù…Ø§Øª TF-IDF
                ngram_range=(1, 2),      # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø§Øª Ù…ÙØ±Ø¯Ø© ÙˆØ«Ù†Ø§Ø¦ÙŠØ©
                max_features=5000,       # Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù…ÙŠØ²Ø§Øª
                lowercase=True,          # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
                stop_words=None,         # Ø¹Ø¯Ù… Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆÙ‚Ù (Ù…Ù‡Ù…Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©)
                min_df=1,                # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø©
                max_df=0.95              # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø©
            )),
            ('classifier', MultinomialNB(
                alpha=1.0                # Ù…Ø¹Ù„Ù…Ø© Ø§Ù„ØªÙ†Ø¹ÙŠÙ…
            ))
        ])
        
        print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")

    def train(self, X_train, y_train):
        """
        Train the sentiment classifier on the provided data.
        
        Args:
            X_train: Training text data (pandas Series or list)
            y_train: Training labels (pandas Series or list)
            
        Returns:
            self: Returns the trained classifier instance for method chaining
        """
        print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(X_train)}")
        
        # Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª
        if hasattr(y_train, 'value_counts'):
            print("ğŸ“‹ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª:")
            for label, count in y_train.value_counts().items():
                print(f"   {label}: {count} Ø¹ÙŠÙ†Ø©")
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.pipeline.fit(X_train, y_train)
        
        print("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
        return self

    def predict(self, X):
        """
        Make predictions on new text data.
        
        Args:
            X: Text data to predict (list, pandas Series, or single string)
            
        Returns:
            numpy.ndarray: Predicted sentiment labels
        """
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if not hasattr(self.pipeline.named_steps['classifier'], 'classes_'):
            raise ValueError("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨! Ø§Ø³ØªØ®Ø¯Ù… train() Ø£ÙˆÙ„Ø§Ù‹.")
        
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Ø¯
        if isinstance(X, str):
            X = [X]
            
        return self.pipeline.predict(X)
    
    def predict_proba(self, X):
        """
        Get prediction probabilities for each class.
        
        Args:
            X: Text data to predict (list, pandas Series, or single string)
            
        Returns:
            numpy.ndarray: Prediction probabilities for each class
        """
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if not hasattr(self.pipeline.named_steps['classifier'], 'classes_'):
            raise ValueError("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨! Ø§Ø³ØªØ®Ø¯Ù… train() Ø£ÙˆÙ„Ø§Ù‹.")
        
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ±Ø¯
        if isinstance(X, str):
            X = [X]
            
        return self.pipeline.predict_proba(X)

    def evaluate(self, X_test, y_test):
        """
        Evaluate the model performance on test data.
        
        Args:
            X_test: Test text data
            y_test: True test labels
            
        Returns:
            dict: Classification report as dictionary
        """
        print("ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        y_pred = self.predict(X_test)
        
        # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ
        print("\n" + "="*60)
        print("ğŸ“ˆ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
        print("="*60)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙƒÙ‚Ø§Ù…ÙˆØ³
        report = classification_report(
            y_test, 
            y_pred, 
            output_dict=True,
            zero_division=0
        )
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù†Ø³Ù‚
        print(classification_report(y_test, y_pred, zero_division=0))
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        accuracy = report['accuracy']
        print(f"ğŸ¯ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {accuracy:.2%}")
        
        # Ù…ØµÙÙˆÙØ© Ø§Ù„Ø®Ù„Ø·
        print(f"\nğŸ“Š Ù…ØµÙÙˆÙØ© Ø§Ù„Ø®Ù„Ø·:")
        cm = confusion_matrix(y_test, y_pred)
        print(cm)
        
        return report

    def save_model(self, path):
        """
        Save the trained model to disk.
        
        Args:
            path: Path to save the model (string or Path object)
        """
        path = Path(path)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        joblib.dump(self.pipeline, path)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {path}")
    
    def load_model(self, path):
        """
        Load a trained model from disk.
        
        Args:
            path: Path to the saved model (string or Path object)
        """
        path = Path(path)
        
        if not path.exists():
            raise FileNotFoundError(f"âŒ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {path}")
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.pipeline = joblib.load(path)
        print(f"ğŸ“‚ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {path}")
    
    def get_feature_names(self):
        """
        Get the feature names from the TF-IDF vectorizer.
        
        Returns:
            numpy.ndarray: Array of feature names
        """
        if not hasattr(self.pipeline.named_steps['tfidf'], 'vocabulary_'):
            raise ValueError("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨! Ø§Ø³ØªØ®Ø¯Ù… train() Ø£ÙˆÙ„Ø§Ù‹.")
        
        return self.pipeline.named_steps['tfidf'].get_feature_names_out()
    
    def get_model_info(self):
        """
        Get information about the trained model.
        
        Returns:
            dict: Model information
        """
        if not hasattr(self.pipeline.named_steps['classifier'], 'classes_'):
            return {"status": "ØºÙŠØ± Ù…Ø¯Ø±Ø¨"}
        
        info = {
            "status": "Ù…Ø¯Ø±Ø¨",
            "classes": list(self.pipeline.named_steps['classifier'].classes_),
            "n_features": len(self.get_feature_names()),
            "vectorizer_params": self.pipeline.named_steps['tfidf'].get_params(),
            "classifier_params": self.pipeline.named_steps['classifier'].get_params()
        }
        
        return info
